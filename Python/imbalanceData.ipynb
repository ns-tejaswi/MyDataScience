{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  balance  var1  var2  var3  var4\n",
       "0       B     1     1     1     1\n",
       "1       R     1     1     1     2\n",
       "2       R     1     1     1     3\n",
       "3       R     1     1     1     4\n",
       "4       R     1     1     1     5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://elitedatascience.com/imbalanced-classes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('balance-scale.data.txt',\n",
    "                names=['balance','var1','var2','var3','var4'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\prassha\\\\Desktop\\\\MachineLearning\\\\Python\\\\ImbalanceData'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L    288\n",
       "R    288\n",
       "B     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.balance.value_counts()  # df['balance'].value_counts()  ## both are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.balance = [1 if b == 'B' else 0 for b in df.balance]\n",
    "df.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis =1)\n",
    "clf_0 = LogisticRegression().fit(X,y)\n",
    "pred_y_0 = clf_0.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:: 0.9216\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_score::\", accuracy_score(pred_y_0,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.unique(pred_y_0):: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"np.unique(pred_y_0)::\", np.unique(pred_y_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##As you can see, this model is only predicting 0, which means it's completely ignoring \n",
    "##the minority class in favor of the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Up-sample Minority Class\n",
    "\n",
    "Next, we'll create a new DataFrame with an up-sampled minority class. Here are the steps:\n",
    "\n",
    "1.First, we'll separate observations from each class into different DataFrames\n",
    "\n",
    "2.Next, we'll resample the minority class with replacement, setting the number of samples to match that of the majority class.\n",
    "\n",
    "3.Finally, we'll combine the up-sampled minority class DataFrame with the original majority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "0    576\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance == 0]\n",
    "df_minority = df[df.balance == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsample = resample(df_minority,\n",
    "                               replace=True,\n",
    "                               n_samples=576,\n",
    "                               random_state=123)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsample])\n",
    "\n",
    "df_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new DataFrame has more observations than the original, and the ratio of the two classes is now 1:1.\n",
    "\n",
    "Let's train another model using Logistic Regression, this time on the balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.unique(pred_y_1):: [0 1]\n"
     ]
    }
   ],
   "source": [
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis =1)\n",
    "\n",
    "clf_1 = LogisticRegression().fit(X,y)\n",
    "pred_y_1 = clf_1.predict(X)\n",
    "print(\"np.unique(pred_y_1)::\", np.unique(pred_y_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score after upscaling:: 0.513888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_score after upscaling::\", accuracy_score(y,pred_y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the model is no longer predicting just one class. While the accuracy also took a nosedive, it's now more meaningful as a performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################################################################\n",
    "2. Down-sample Majority Class\n",
    "Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "\n",
    "The most common heuristic for doing so is resampling without replacement.\n",
    "\n",
    "The process is similar to that of up-sampling. Here are the steps:\n",
    "\n",
    "1.First, we'll separate observations from each class into different DataFrames.\n",
    "\n",
    "2.Next, we'll resample the majority class without replacement, setting the number of samples to match that of the minority class.\n",
    "\n",
    "3.Finally, we'll combine the down-sampled majority class DataFrame with the original minority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    49\n",
       "0    49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance == 0]\n",
    "df_minority = df[df.balance == 1]\n",
    "\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                  replace=False,\n",
    "                                  n_samples = 49,\n",
    "                                  random_state = 123)\n",
    "\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled,df_minority])\n",
    "\n",
    "df_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#####  https://elitedatascience.com/imbalanced-classes\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis = 1)\n",
    "\n",
    "clf_2 = LogisticRegression().fit(X,y)\n",
    "\n",
    "pred_y_2 = clf_2.predict(X)\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print(np.unique(pred_y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581632653061\n"
     ]
    }
   ],
   "source": [
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model isn't predicting just one class, and the accuracy seems higher.\n",
    "\n",
    "We'd still want to validate the model on an unseen test dataset, but the results are more encouraging.\n",
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion::\n",
      " [[29 20]\n",
      " [21 28]]\n",
      "Accuracy: 0.58\n",
      "Precision: 0.58\n",
      "Recall: 0.57\n",
      "F1: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y, pred_y_2)\n",
    "print(\"confusion::\\n\", confusion)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y, pred_y_2)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y, pred_y_2)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y, pred_y_2)))\n",
    "print('F1: {:.2f}'.format(f1_score(y, pred_y_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_2_decisionFunction = clf_2.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18374736, -0.07179233, -0.12567206, -0.08531656,  0.32868165,\n",
       "        0.23457575, -0.29533321,  0.32676845, -0.0676336 ,  0.2507147 ,\n",
       "       -0.12292802, -0.22185732,  0.31099869,  0.32918016,  0.21705896,\n",
       "        0.15677497, -0.21753242, -0.16361585,  0.23216405, -0.21927945,\n",
       "       -0.29549938, -0.21495455,  0.14133754,  0.08035203,  0.19904366,\n",
       "       -0.20176266,  0.0848431 , -0.21961179, -0.23696242, -0.09172083,\n",
       "        0.28882466, -0.08273869, -0.12342652, -0.27781642,  0.25329257,\n",
       "       -0.10333186, -0.03176917, -0.04687426,  0.29107019, -0.01150834,\n",
       "        0.1546956 , -0.0719585 ,  0.10285839,  0.0401627 , -0.16348653,\n",
       "       -0.25481155, -0.21686775, -0.29500087,  0.29298339, -0.21462222,\n",
       "       -0.06472339, -0.19693925,  0.08517543, -0.17925629,  0.23507426,\n",
       "       -0.0291913 , -0.16157333,  0.38497308, -0.14389037, -0.10266719,\n",
       "       -0.23488305,  0.17928133, -0.08498422, -0.21736625,  0.0649146 ,\n",
       "       -0.06730126,  0.21481342, -0.0496183 ,  0.36471225, -0.03193534,\n",
       "        0.00928784, -0.25514388,  0.02697081, -0.10524506,  0.04465377,\n",
       "        0.19455259,  0.06233673,  0.34445142,  0.08001969,  0.12124287,\n",
       "       -0.14302268, -0.27540471,  0.13892584, -0.12550589,  0.1566088 ,\n",
       "        0.02439294,  0.17429176,  0.32419058,  0.19197472,  0.2331979 ,\n",
       "       -0.29566554,  0.25088087, -0.14576672,  0.26856383,  0.0041321 ,\n",
       "        0.28624679,  0.15403093,  0.30392975])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2_decisionFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -0.18374736130018848),\n",
       " (0, -0.071792331220603911),\n",
       " (0, -0.12567205631383987),\n",
       " (0, -0.085316560053083912),\n",
       " (0, 0.32868165310553532),\n",
       " (0, 0.23457575297938416),\n",
       " (0, -0.29533320975821026),\n",
       " (0, 0.3267684539697604),\n",
       " (0, -0.067633597716118377),\n",
       " (0, 0.25071469780213762),\n",
       " (0, -0.12292801909572568),\n",
       " (0, -0.22185732319223381),\n",
       " (0, 0.31099869076856979),\n",
       " (0, 0.32918015595493888),\n",
       " (0, 0.21705895825888655),\n",
       " (0, 0.15677496529245438),\n",
       " (0, -0.2175324220712804),\n",
       " (0, -0.16361585058941736),\n",
       " (0, 0.23216405099420567),\n",
       " (0, -0.21927945359058745),\n",
       " (0, -0.29549937737467813),\n",
       " (0, -0.21495455246963405),\n",
       " (0, 0.1413375373241994),\n",
       " (0, 0.080352027503268753),\n",
       " (0, 0.19904366068898527),\n",
       " (0, -0.20176265887008976),\n",
       " (0, 0.08484309624069003),\n",
       " (0, -0.21961178882352317),\n",
       " (0, -0.23696241592755302),\n",
       " (0, -0.091720827926280113),\n",
       " (0, 0.28882465969418292),\n",
       " (0, -0.082738690451437558),\n",
       " (0, -0.12342652194512926),\n",
       " (0, -0.27781641503771254),\n",
       " (0, 0.25329256740378403),\n",
       " (0, -0.10333185762298519),\n",
       " (0, -0.031769170192783691),\n",
       " (0, -0.046874262928102872),\n",
       " (0, 0.29107019406289358),\n",
       " (0, -0.011508338254171746),\n",
       " (0, 0.15469559854021159),\n",
       " (0, -0.071958498837071783),\n",
       " (0, 0.10285839381059131),\n",
       " (0, 0.040162698858980661),\n",
       " (0, -0.16348652936157657),\n",
       " (0, -0.25481154588098642),\n",
       " (0, -0.21686775160540894),\n",
       " (0, -0.29500087452527451),\n",
       " (0, 0.29298339319866851),\n",
       " (1, -0.2146222172366983),\n",
       " (1, -0.064723392881536279),\n",
       " (1, -0.19693925489973277),\n",
       " (1, 0.085175431473625773),\n",
       " (1, -0.17925629256276721),\n",
       " (1, 0.23507425582878783),\n",
       " (1, -0.029191300591137281),\n",
       " (1, -0.16157333022580164),\n",
       " (1, 0.38497308018394982),\n",
       " (1, -0.14389036788883608),\n",
       " (1, -0.10266718715711376),\n",
       " (1, -0.23488304917531022),\n",
       " (1, 0.17928133159977688),\n",
       " (1, -0.084984224820148169),\n",
       " (1, -0.21736625445481253),\n",
       " (1, 0.064914599535013828),\n",
       " (1, -0.067301262483182633),\n",
       " (1, 0.21481342389017588),\n",
       " (1, -0.049618300146217098),\n",
       " (1, 0.36471224824533788),\n",
       " (1, -0.031935337809251507),\n",
       " (1, 0.0092878429224708126),\n",
       " (1, -0.25514388111392217),\n",
       " (1, 0.026970805259436348),\n",
       " (1, -0.10524505675876011),\n",
       " (1, 0.044653767596401939),\n",
       " (1, 0.19455259195156394),\n",
       " (1, 0.062336729933367474),\n",
       " (1, 0.34445141630672604),\n",
       " (1, 0.080019692270333065),\n",
       " (1, 0.12124287300205538),\n",
       " (1, -0.14302268341786972),\n",
       " (1, -0.27540471305253406),\n",
       " (1, 0.13892583533902092),\n",
       " (1, -0.12550588869737203),\n",
       " (1, 0.15660879767598646),\n",
       " (1, 0.024392935657789994),\n",
       " (1, 0.1742917600129521),\n",
       " (1, 0.3241905843681141),\n",
       " (1, 0.19197472234991764),\n",
       " (1, 0.2331979030816399),\n",
       " (1, -0.29566554499114595),\n",
       " (1, 0.25088086541860555),\n",
       " (1, -0.14576672063598392),\n",
       " (1, 0.26856382775557108),\n",
       " (1, 0.004132103719178104),\n",
       " (1, 0.28624679009253662),\n",
       " (1, 0.15403092807434016),\n",
       " (1, 0.30392975242950215)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2_y_score_list = list(zip(y, clf_2_decisionFunction))\n",
    "clf_2_y_score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change Your Performance Metric\n",
    "So far, we've looked at two ways of addressing imbalanced classes by resampling the dataset. Next, we'll look at using other performance metrics for evaluating the models.\n",
    "\n",
    "Albert Einstein once said, \"if you judge a fish on its ability to climb a tree, it will live its whole life believing that it is stupid.\" This quote really highlights the importance of choosing the right evaluation metric.\n",
    "\n",
    "For a general-purpose metric for classification, we recommend Area Under ROC Curve (AUROC).\n",
    "\n",
    "We won't dive into its details in this guide, but you can read more about it here.\n",
    "Intuitively, AUROC represents the likelihood of your model distinguishing observations from two classes.\n",
    "In other words, if you randomly select one observation from each class, what's the probability that your model will be able to \"rank\" them correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54580803,  0.45419197],\n",
       "       [ 0.51794038,  0.48205962],\n",
       "       [ 0.53137673,  0.46862327],\n",
       "       [ 0.52131621,  0.47868379],\n",
       "       [ 0.41856143,  0.58143857],\n",
       "       [ 0.4416235 ,  0.5583765 ],\n",
       "       [ 0.57330129,  0.42669871],\n",
       "       [ 0.41902712,  0.58097288],\n",
       "       [ 0.51690196,  0.48309804],\n",
       "       [ 0.4376476 ,  0.5623524 ],\n",
       "       [ 0.53069336,  0.46930664],\n",
       "       [ 0.55523795,  0.44476205],\n",
       "       [ 0.42287099,  0.57712901],\n",
       "       [ 0.41844012,  0.58155988],\n",
       "       [ 0.44594732,  0.55405268],\n",
       "       [ 0.46088634,  0.53911366],\n",
       "       [ 0.55416966,  0.44583034],\n",
       "       [ 0.54081296,  0.45918704],\n",
       "       [ 0.44221829,  0.55778171],\n",
       "       [ 0.55460125,  0.44539875],\n",
       "       [ 0.57334194,  0.42665806],\n",
       "       [ 0.55353267,  0.44646733],\n",
       "       [ 0.46472432,  0.53527568],\n",
       "       [ 0.47992279,  0.52007721],\n",
       "       [ 0.45040272,  0.54959728],\n",
       "       [ 0.55027025,  0.44972975],\n",
       "       [ 0.47880194,  0.52119806],\n",
       "       [ 0.55468335,  0.44531665],\n",
       "       [ 0.55896495,  0.44103505],\n",
       "       [ 0.52291415,  0.47708585],\n",
       "       [ 0.42829163,  0.57170837],\n",
       "       [ 0.52067288,  0.47932712],\n",
       "       [ 0.53081752,  0.46918248],\n",
       "       [ 0.56901081,  0.43098919],\n",
       "       [ 0.43701325,  0.56298675],\n",
       "       [ 0.52581   ,  0.47419   ],\n",
       "       [ 0.50794162,  0.49205838],\n",
       "       [ 0.51171642,  0.48828358],\n",
       "       [ 0.42774189,  0.57225811],\n",
       "       [ 0.50287705,  0.49712295],\n",
       "       [ 0.46140304,  0.53859696],\n",
       "       [ 0.51798187,  0.48201813],\n",
       "       [ 0.47430805,  0.52569195],\n",
       "       [ 0.48996067,  0.51003933],\n",
       "       [ 0.54078084,  0.45921916],\n",
       "       [ 0.56336043,  0.43663957],\n",
       "       [ 0.55400544,  0.44599456],\n",
       "       [ 0.57321999,  0.42678001],\n",
       "       [ 0.42727364,  0.57272636],\n",
       "       [ 0.55345054,  0.44654946],\n",
       "       [ 0.5161752 ,  0.4838248 ],\n",
       "       [ 0.5490763 ,  0.4509237 ],\n",
       "       [ 0.47871901,  0.52128099],\n",
       "       [ 0.54469446,  0.45530554],\n",
       "       [ 0.44150058,  0.55849942],\n",
       "       [ 0.50729731,  0.49270269],\n",
       "       [ 0.54030569,  0.45969431],\n",
       "       [ 0.40492801,  0.59507199],\n",
       "       [ 0.53591065,  0.46408935],\n",
       "       [ 0.52564428,  0.47435572],\n",
       "       [ 0.55845227,  0.44154773],\n",
       "       [ 0.45529933,  0.54470067],\n",
       "       [ 0.52123328,  0.47876672],\n",
       "       [ 0.55412861,  0.44587139],\n",
       "       [ 0.48377705,  0.51622295],\n",
       "       [ 0.51681897,  0.48318103],\n",
       "       [ 0.44650221,  0.55349779],\n",
       "       [ 0.51240203,  0.48759797],\n",
       "       [ 0.40981934,  0.59018066],\n",
       "       [ 0.50798316,  0.49201684],\n",
       "       [ 0.49767806,  0.50232194],\n",
       "       [ 0.56344218,  0.43655782],\n",
       "       [ 0.49325771,  0.50674229],\n",
       "       [ 0.526287  ,  0.473713  ],\n",
       "       [ 0.48883841,  0.51116159],\n",
       "       [ 0.45151469,  0.54848531],\n",
       "       [ 0.48442086,  0.51557914],\n",
       "       [ 0.41472858,  0.58527142],\n",
       "       [ 0.48000574,  0.51999426],\n",
       "       [ 0.46972636,  0.53027364],\n",
       "       [ 0.53569485,  0.46430515],\n",
       "       [ 0.56841927,  0.43158073],\n",
       "       [ 0.46532429,  0.53467571],\n",
       "       [ 0.53133535,  0.46866465],\n",
       "       [ 0.46092763,  0.53907237],\n",
       "       [ 0.49390207,  0.50609793],\n",
       "       [ 0.45653703,  0.54346297],\n",
       "       [ 0.41965481,  0.58034519],\n",
       "       [ 0.45215318,  0.54784682],\n",
       "       [ 0.4419633 ,  0.5580367 ],\n",
       "       [ 0.57338258,  0.42661742],\n",
       "       [ 0.4376067 ,  0.5623933 ],\n",
       "       [ 0.53637729,  0.46362271],\n",
       "       [ 0.43325971,  0.56674029],\n",
       "       [ 0.49896698,  0.50103302],\n",
       "       [ 0.42892296,  0.57107704],\n",
       "       [ 0.46156822,  0.53843178],\n",
       "       [ 0.4245971 ,  0.5754029 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Predict class probabilities\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    "prob_y_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45419197226479618,\n",
       " 0.48205962213283882,\n",
       " 0.46862327066392495,\n",
       " 0.47868378832689129,\n",
       " 0.58143856820159712]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2 ]\n",
    "prob_y_2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.568096626406\n",
      "###################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASYAAAEdCAYAAAChecq0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7dde526d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, threshold = roc_curve(y,prob_y_2)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(\"roc_auc:\",roc_auc)\n",
    "print(\"###################################\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr, tpr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve balance', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:: 0.568096626406\n"
     ]
    }
   ],
   "source": [
    "###So how did this model (trained on the down-sampled dataset) do in terms of AUROC?\n",
    "print(\"roc_auc_score::\", roc_auc_score(y,prob_y_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... and how does this compare to the original model trained on the imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:: 0.474802165764\n"
     ]
    }
   ],
   "source": [
    "prob_y_0 = clf_0.predict_proba(X)\n",
    "prob_y_0 = [p[1] for p in prob_y_0]\n",
    "print(\"roc_auc_score::\", roc_auc_score(y,prob_y_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Penalize Algorithms (Cost-Sensitive Training)\n",
    "\n",
    "The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class.\n",
    "\n",
    "A popular algorithm for this technique is Penalized-SVM:\n",
    "\n",
    "Support Vector MachinePython\n",
    "1\n",
    "from sklearn.svm import SVC\n",
    "During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "We also want to include the argument probability=True  if we want to enable probability estimates for SVM algorithms.\n",
    "\n",
    "Let's train a model using Penalized-SVM on the original imbalanced dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    576\n",
      "1     49\n",
      "Name: balance, dtype: int64\n",
      "np.unique(pred_y_3): [0 1]\n",
      "accuracy_score: 0.688\n",
      "roc_auc_score(y, prob_y_3): 0.4694763322\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis = 1)\n",
    "print(y.value_counts())\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_3 = SVC(kernel='linear',\n",
    "           class_weight='balanced',#penelize\n",
    "           probability=True)\n",
    "clf_3.fit(X,y)\n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X)\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('np.unique(pred_y_3):', np.unique(pred_y_3))\n",
    "\n",
    "print(\"accuracy_score:\", accuracy_score(y, pred_y_3))\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "\n",
    "print(\"roc_auc_score(y, prob_y_3):\", roc_auc_score(y,prob_y_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter(accuracy):: {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Grid best score(accuracy): 0.9216\n",
      "#######################################################################################################\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "Grid best parameter(roc):: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Grid best score(roc): 0.887324509804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "### lets apply Grid search in SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf_GS = SVC();\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['linear','rbf']\n",
    "params_grid = {'kernel': kernels, 'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "grid_search_acc = GridSearchCV(clf_GS, param_grid = params_grid, scoring='accuracy', n_jobs = -1,verbose =2  )\n",
    "grid_search_acc.fit(X,y)\n",
    "\n",
    "print('Grid best parameter(accuracy)::', grid_search_acc.best_params_)\n",
    "print('Grid best score(accuracy):', grid_search_acc.best_score_)\n",
    "\n",
    "print(\"#######################################################################################################\")\n",
    "\n",
    "grid_search_roc = GridSearchCV(clf_GS, param_grid = params_grid, scoring='roc_auc', n_jobs = -1,verbose = 1 )\n",
    "\n",
    "grid_search_roc.fit(X,y)\n",
    "\n",
    "print('Grid best parameter(roc)::', grid_search_roc.best_params_)\n",
    "print('Grid best score(roc):', grid_search_roc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################\n",
    "5. Use Tree-Based Algorithms\n",
    "\n",
    "The final tactic we'll consider is using tree-based algorithms. Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes.\n",
    "\n",
    "In modern applied machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we'll jump right into those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.value_counts(): 0    576\n",
      "1     49\n",
      "Name: balance, dtype: int64\n",
      "np.unique( pred_y_4 ):: [0 1]\n",
      "accuracy_score(y,pred_y_4): 0.9792\n",
      "roc_auc_score(y, prob_y_4): 0.999415391156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    "print(\"y.value_counts():\", y.value_counts())\n",
    "\n",
    "clf_4 = RandomForestClassifier().fit(X,y)\n",
    "# Predict on training set\n",
    "pred_y_4 = clf_4.predict(X)\n",
    "# Is our model still predicting just one class?\n",
    "print('np.unique( pred_y_4 )::', np.unique( pred_y_4 ) )\n",
    "\n",
    "# How's our accuracy?\n",
    "print('accuracy_score(y,pred_y_4):',accuracy_score(y,pred_y_4))\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X)\n",
    "prob_y_4 =[p[1] for p in prob_y_4]\n",
    "print('roc_auc_score(y, prob_y_4):',roc_auc_score(y, prob_y_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
