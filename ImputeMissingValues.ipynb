{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Example taken from :: https://machinelearningmastery.com/handle-missing-data-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pima Indians Diabetes Dataset\n",
    "\n",
    "\n",
    "The Pima Indians Diabetes Dataset involves predicting the onset of diabetes within 5 years in Pima Indians given medical details.\n",
    "\n",
    "It is a binary (2-class) classification problem. The number of observations for each class is not balanced. There are 768 observations with 8 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "0. Number of times pregnant.\n",
    "1. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "2. Diastolic blood pressure (mm Hg).\n",
    "3. Triceps skinfold thickness (mm).\n",
    "4. 2-Hour serum insulin (mu U/ml).\n",
    "5. Body mass index (weight in kg/(height in m)^2).\n",
    "6. Diabetes pedigree function.\n",
    "7. Age (years).\n",
    "8. Class variable (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('pima-indians-diabetes.data.txt', header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful.\n",
    "\n",
    "We can see that there are columns that have a minimum value of zero (0). On some columns, a value of zero does not make sense and indicates an invalid or missing value.\n",
    "\n",
    "Specifically, the following columns have an invalid zero minimum value:\n",
    "\n",
    "1: Plasma glucose concentration\n",
    "2: Diastolic blood pressure\n",
    "3: Triceps skinfold thickness\n",
    "4: 2-Hour serum insulin\n",
    "5: Body mass index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################################\n",
    "We can get a count of the number of missing values on each of these columns. We can do this my marking all of the values in the subset of the DataFrame we are interested in that have zero values as True. We can then count the number of true values in each column.\n",
    "\n",
    "We can do this my marking all of the values in the subset of the DataFrame we are interested in that have zero values as True. We can then count the number of true values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((dataset[[1,2,3,4,5]]== 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, specifically Pandas, NumPy and Scikit-Learn, we mark missing values as NaN.\n",
    "\n",
    "Values with a NaN value are ignored from operations like sum, count, etc.\n",
    "\n",
    "We can mark values as NaN easily with the Pandas DataFrame by using the replace() function on a subset of the columns we are interested in.\n",
    "\n",
    "After we have marked the missing values, we can use the isnull() function to mark all of the NaN values in the dataset as True and get a count of the missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN )\n",
    "\n",
    "# count the number of NaN values in each column\n",
    "print(dataset.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Missing Values Causes Problems\n",
    "\n",
    "Having missing values in a dataset can cause errors with some machine learning algorithms.\n",
    "\n",
    "In this section, we will try to evaluate a the Linear Discriminant Analysis (LDA) algorithm on the dataset with missing values.\n",
    "\n",
    "This is an algorithm that does not work when there are missing values in the dataset.\n",
    "\n",
    "The below example marks the missing values in the dataset, as we did in the previous section, then attempts to evaluate LDA using 3-fold cross validation and print the mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8def58b992d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.mean():'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, store_covariance, tol)\u001b[0m\n\u001b[0;32m    440\u001b[0m                           DeprecationWarning)\n\u001b[0;32m    441\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\prassha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values   ## generated matrix out of the dataframe\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "kfold = KFold(n_splits =3 , random_state = 7)\n",
    "result = cross_val_score(model,X, y, cv= kfold, scoring = 'accuracy' )\n",
    "print('result.mean():', result.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as we expect.\n",
    "\n",
    "We are prevented from evaluating an LDA algorithm (and other algorithms) on the dataset with missing values.\n",
    "\n",
    "Now, we can look at methods to handle the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################\n",
    "4. Remove Rows With Missing Values\n",
    "\n",
    "The simplest strategy for handling missing data is to remove records that contain a missing value.\n",
    "\n",
    "We can do this by creating a new Pandas DataFrame with the rows containing missing values removed.\n",
    "\n",
    "Pandas provides the dropna() function that can be used to drop either columns or rows with missing data. We can use dropna() to remove all rows with missing data, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with missing values\n",
    "dataset.dropna(inplace = True)\n",
    "# summarize the number of rows and columns in the dataset\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that we could use to evaluate an algorithm sensitive to missing values like LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.mean(): 0.78582892934\n"
     ]
    }
   ],
   "source": [
    "values = dataset.values   ## generated matrix out of the dataframe\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "kfold = KFold(n_splits =3 , random_state = 7)\n",
    "result = cross_val_score(model,X, y, cv= kfold, scoring = 'accuracy' )\n",
    "print('result.mean():', result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows with missing values can be too limiting on some predictive modeling problems, an alternative is to impute missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('pima-indians-diabetes.data.txt', header=None)\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "\n",
    "# fill missing values with mean column values\n",
    "dataset.fillna(dataset.mean(), inplace = True)\n",
    "\n",
    "# count the number of NaN values in each column\n",
    "print(dataset.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scikit-learn library provides the Imputer() pre-processing class that can be used to replace missing values.\n",
    "\n",
    "It is a flexible class that allows you to specify the value to replace (it can be something other than NaN) and the technique used to replace it (such as mean, median, or mode). The Imputer class operates directly on the NumPy array instead of the DataFrame.\n",
    "\n",
    "The example below uses the Imputer class to replace missing values with the mean of each column then prints the number of NaN values in the transformed matrix. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#values = dataset.values   ## generated matrix out of the dataframe\n",
    "#X = values[:,:8]\n",
    "#y = values[:,8]\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'mean', axis =0)\n",
    "imp.fit(dataset)   ######## working\n",
    "print(dataset.isnull().sum())  ###### working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "dtype: int64\n",
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7\n",
       "0  6  148  72  35    0  33.6  0.627  50\n",
       "1  1   85  66  29    0  26.6  0.351  31\n",
       "2  8  183  64   0    0  23.3  0.672  32\n",
       "3  1   89  66  23   94  28.1  0.167  21\n",
       "4  0  137  40  35  168  43.1  2.288  33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pima-indians-diabetes.data.txt', header=None)\n",
    "\n",
    "y = df[8]\n",
    "X = df.drop(8, axis =1)\n",
    "\n",
    "#print((X[[1,2,3,4,5]]== 0).sum())   # works\n",
    "print((X == 0).sum()) # also works\n",
    "imp = Imputer(missing_values = 0, strategy = 'mean', axis =0)\n",
    "imp.fit(X)   ######## working\n",
    "print((X == 0).sum())  ###### working\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-bb4eaf556e48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_imp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pima-indians-diabetes.data.txt', header=None)\n",
    "\n",
    "y = df[8]\n",
    "X = df.drop(8, axis =1)\n",
    "\n",
    "print((X == 0).sum()) # also works\n",
    "imp = Imputer(missing_values = 0, strategy = 'mean', axis =0)\n",
    "X_imp = imp.fit_transform(X)\n",
    "print((X_imp == 0).sum())\n",
    "X_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/33660836/impute-entire-dataframe-all-columns-using-scikit-learn-sklearn-without-itera\n",
    "If you want the mean or median you could do something like:\n",
    "\n",
    "fill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=1)\n",
    "imputed_DF = pd.DataFrame(fill_NaN.fit_transform(DF))\n",
    "imputed_DF.columns = DF.columns\n",
    "imputed_DF.index = DF.index\n",
    "If you want to fill them with 0s or something you could always just do:\n",
    "\n",
    "DF[DF.isnull()] = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1   2   3    4     5      6   7\n",
      "0     6  148  72  35    0  33.6  0.627  50\n",
      "1     1   85  66  29    0  26.6  0.351  31\n",
      "2     8  183  64   0    0  23.3  0.672  32\n",
      "3     1   89  66  23   94  28.1  0.167  21\n",
      "4     0  137  40  35  168  43.1  2.288  33\n",
      "5     5  116  74   0    0  25.6  0.201  30\n",
      "6     3   78  50  32   88  31.0  0.248  26\n",
      "7    10  115   0   0    0  35.3  0.134  29\n",
      "8     2  197  70  45  543  30.5  0.158  53\n",
      "9     8  125  96   0    0   0.0  0.232  54\n",
      "10    4  110  92   0    0  37.6  0.191  30\n",
      "11   10  168  74   0    0  38.0  0.537  34\n",
      "12   10  139  80   0    0  27.1  1.441  57\n",
      "13    1  189  60  23  846  30.1  0.398  59\n",
      "14    5  166  72  19  175  25.8  0.587  51\n",
      "15    7  100   0   0    0  30.0  0.484  32\n",
      "16    0  118  84  47  230  45.8  0.551  31\n",
      "17    7  107  74   0    0  29.6  0.254  31\n",
      "18    1  103  30  38   83  43.3  0.183  33\n",
      "19    1  115  70  30   96  34.6  0.529  32\n",
      "20    3  126  88  41  235  39.3  0.704  27\n",
      "21    8   99  84   0    0  35.4  0.388  50\n",
      "22    7  196  90   0    0  39.8  0.451  41\n",
      "23    9  119  80  35    0  29.0  0.263  29\n",
      "24   11  143  94  33  146  36.6  0.254  51\n",
      "25   10  125  70  26  115  31.1  0.205  41\n",
      "26    7  147  76   0    0  39.4  0.257  43\n",
      "27    1   97  66  15  140  23.2  0.487  22\n",
      "28   13  145  82  19  110  22.2  0.245  57\n",
      "29    5  117  92   0    0  34.1  0.337  38\n",
      "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
      "738   2   99  60  17  160  36.6  0.453  21\n",
      "739   1  102  74   0    0  39.5  0.293  42\n",
      "740  11  120  80  37  150  42.3  0.785  48\n",
      "741   3  102  44  20   94  30.8  0.400  26\n",
      "742   1  109  58  18  116  28.5  0.219  22\n",
      "743   9  140  94   0    0  32.7  0.734  45\n",
      "744  13  153  88  37  140  40.6  1.174  39\n",
      "745  12  100  84  33  105  30.0  0.488  46\n",
      "746   1  147  94  41    0  49.3  0.358  27\n",
      "747   1   81  74  41   57  46.3  1.096  32\n",
      "748   3  187  70  22  200  36.4  0.408  36\n",
      "749   6  162  62   0    0  24.3  0.178  50\n",
      "750   4  136  70   0    0  31.2  1.182  22\n",
      "751   1  121  78  39   74  39.0  0.261  28\n",
      "752   3  108  62  24    0  26.0  0.223  25\n",
      "753   0  181  88  44  510  43.3  0.222  26\n",
      "754   8  154  78  32    0  32.4  0.443  45\n",
      "755   1  128  88  39  110  36.5  1.057  37\n",
      "756   7  137  90  41    0  32.0  0.391  39\n",
      "757   0  123  72   0    0  36.3  0.258  52\n",
      "758   1  106  76   0    0  37.5  0.197  26\n",
      "759   6  190  92   0    0  35.5  0.278  66\n",
      "760   2   88  58  26   16  28.4  0.766  22\n",
      "761   9  170  74  31    0  44.0  0.403  43\n",
      "762   9   89  62   0    0  22.5  0.142  33\n",
      "763  10  101  76  48  180  32.9  0.171  63\n",
      "764   2  122  70  27    0  36.8  0.340  27\n",
      "765   5  121  72  23  112  26.2  0.245  30\n",
      "766   1  126  60   0    0  30.1  0.349  47\n",
      "767   1   93  70  31    0  30.4  0.315  23\n",
      "\n",
      "[768 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pima-indians-diabetes.data.txt', header=None)\n",
    "\n",
    "#values = df.values\n",
    "#X = values[:,0:8]\n",
    "#y = values[:,8]\n",
    "y = df[8]\n",
    "X = df.drop(8, axis =1)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.494673</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.494673</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>39.300000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>196.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>143.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>42.300000</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>49.300000</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>121.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>4.494673</td>\n",
       "      <td>181.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>137.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>4.494673</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1          2         3           4          5      6     7\n",
       "0     6.000000  148.0  72.000000  35.00000  155.548223  33.600000  0.627  50.0\n",
       "1     1.000000   85.0  66.000000  29.00000  155.548223  26.600000  0.351  31.0\n",
       "2     8.000000  183.0  64.000000  29.15342  155.548223  23.300000  0.672  32.0\n",
       "3     1.000000   89.0  66.000000  23.00000   94.000000  28.100000  0.167  21.0\n",
       "4     4.494673  137.0  40.000000  35.00000  168.000000  43.100000  2.288  33.0\n",
       "5     5.000000  116.0  74.000000  29.15342  155.548223  25.600000  0.201  30.0\n",
       "6     3.000000   78.0  50.000000  32.00000   88.000000  31.000000  0.248  26.0\n",
       "7    10.000000  115.0  72.405184  29.15342  155.548223  35.300000  0.134  29.0\n",
       "8     2.000000  197.0  70.000000  45.00000  543.000000  30.500000  0.158  53.0\n",
       "9     8.000000  125.0  96.000000  29.15342  155.548223  32.457464  0.232  54.0\n",
       "10    4.000000  110.0  92.000000  29.15342  155.548223  37.600000  0.191  30.0\n",
       "11   10.000000  168.0  74.000000  29.15342  155.548223  38.000000  0.537  34.0\n",
       "12   10.000000  139.0  80.000000  29.15342  155.548223  27.100000  1.441  57.0\n",
       "13    1.000000  189.0  60.000000  23.00000  846.000000  30.100000  0.398  59.0\n",
       "14    5.000000  166.0  72.000000  19.00000  175.000000  25.800000  0.587  51.0\n",
       "15    7.000000  100.0  72.405184  29.15342  155.548223  30.000000  0.484  32.0\n",
       "16    4.494673  118.0  84.000000  47.00000  230.000000  45.800000  0.551  31.0\n",
       "17    7.000000  107.0  74.000000  29.15342  155.548223  29.600000  0.254  31.0\n",
       "18    1.000000  103.0  30.000000  38.00000   83.000000  43.300000  0.183  33.0\n",
       "19    1.000000  115.0  70.000000  30.00000   96.000000  34.600000  0.529  32.0\n",
       "20    3.000000  126.0  88.000000  41.00000  235.000000  39.300000  0.704  27.0\n",
       "21    8.000000   99.0  84.000000  29.15342  155.548223  35.400000  0.388  50.0\n",
       "22    7.000000  196.0  90.000000  29.15342  155.548223  39.800000  0.451  41.0\n",
       "23    9.000000  119.0  80.000000  35.00000  155.548223  29.000000  0.263  29.0\n",
       "24   11.000000  143.0  94.000000  33.00000  146.000000  36.600000  0.254  51.0\n",
       "25   10.000000  125.0  70.000000  26.00000  115.000000  31.100000  0.205  41.0\n",
       "26    7.000000  147.0  76.000000  29.15342  155.548223  39.400000  0.257  43.0\n",
       "27    1.000000   97.0  66.000000  15.00000  140.000000  23.200000  0.487  22.0\n",
       "28   13.000000  145.0  82.000000  19.00000  110.000000  22.200000  0.245  57.0\n",
       "29    5.000000  117.0  92.000000  29.15342  155.548223  34.100000  0.337  38.0\n",
       "..         ...    ...        ...       ...         ...        ...    ...   ...\n",
       "738   2.000000   99.0  60.000000  17.00000  160.000000  36.600000  0.453  21.0\n",
       "739   1.000000  102.0  74.000000  29.15342  155.548223  39.500000  0.293  42.0\n",
       "740  11.000000  120.0  80.000000  37.00000  150.000000  42.300000  0.785  48.0\n",
       "741   3.000000  102.0  44.000000  20.00000   94.000000  30.800000  0.400  26.0\n",
       "742   1.000000  109.0  58.000000  18.00000  116.000000  28.500000  0.219  22.0\n",
       "743   9.000000  140.0  94.000000  29.15342  155.548223  32.700000  0.734  45.0\n",
       "744  13.000000  153.0  88.000000  37.00000  140.000000  40.600000  1.174  39.0\n",
       "745  12.000000  100.0  84.000000  33.00000  105.000000  30.000000  0.488  46.0\n",
       "746   1.000000  147.0  94.000000  41.00000  155.548223  49.300000  0.358  27.0\n",
       "747   1.000000   81.0  74.000000  41.00000   57.000000  46.300000  1.096  32.0\n",
       "748   3.000000  187.0  70.000000  22.00000  200.000000  36.400000  0.408  36.0\n",
       "749   6.000000  162.0  62.000000  29.15342  155.548223  24.300000  0.178  50.0\n",
       "750   4.000000  136.0  70.000000  29.15342  155.548223  31.200000  1.182  22.0\n",
       "751   1.000000  121.0  78.000000  39.00000   74.000000  39.000000  0.261  28.0\n",
       "752   3.000000  108.0  62.000000  24.00000  155.548223  26.000000  0.223  25.0\n",
       "753   4.494673  181.0  88.000000  44.00000  510.000000  43.300000  0.222  26.0\n",
       "754   8.000000  154.0  78.000000  32.00000  155.548223  32.400000  0.443  45.0\n",
       "755   1.000000  128.0  88.000000  39.00000  110.000000  36.500000  1.057  37.0\n",
       "756   7.000000  137.0  90.000000  41.00000  155.548223  32.000000  0.391  39.0\n",
       "757   4.494673  123.0  72.000000  29.15342  155.548223  36.300000  0.258  52.0\n",
       "758   1.000000  106.0  76.000000  29.15342  155.548223  37.500000  0.197  26.0\n",
       "759   6.000000  190.0  92.000000  29.15342  155.548223  35.500000  0.278  66.0\n",
       "760   2.000000   88.0  58.000000  26.00000   16.000000  28.400000  0.766  22.0\n",
       "761   9.000000  170.0  74.000000  31.00000  155.548223  44.000000  0.403  43.0\n",
       "762   9.000000   89.0  62.000000  29.15342  155.548223  22.500000  0.142  33.0\n",
       "763  10.000000  101.0  76.000000  48.00000  180.000000  32.900000  0.171  63.0\n",
       "764   2.000000  122.0  70.000000  27.00000  155.548223  36.800000  0.340  27.0\n",
       "765   5.000000  121.0  72.000000  23.00000  112.000000  26.200000  0.245  30.0\n",
       "766   1.000000  126.0  60.000000  29.15342  155.548223  30.100000  0.349  47.0\n",
       "767   1.000000   93.0  70.000000  31.00000  155.548223  30.400000  0.315  23.0\n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = Imputer(missing_values = 0, strategy = 'mean', axis =0)\n",
    "X_imp = pd.DataFrame(imp.fit_transform(X))\n",
    "X_imp.columns = X.columns\n",
    "X_imp.index = X.index\n",
    "print((X_imp == 0).sum())\n",
    "X_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
